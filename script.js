// DOM Elements
const recordButton = document.getElementById('recordButton');
const recordingStatus = document.getElementById('recordingStatus');
const recordingTimer = document.getElementById('recordingTimer');
const visualizer = document.getElementById('visualizer');
const recognitionStatus = document.getElementById('recognitionStatus');
const conversationText = document.getElementById('conversationText');
const agentJoker = document.getElementById('agent-joker');
const agentSkeptic = document.getElementById('agent-skeptic');
const agentSmart = document.getElementById('agent-smart');
const sendFrequency = document.getElementById('sendFrequency');
const frequencyValue = document.getElementById('frequencyValue');
const autoSendToggle = document.getElementById('autoSendToggle');
const playButton = document.getElementById('playButton');
const recognizeButton = document.getElementById('recognizeButton');

// Audio Recording System (Composition pattern)
const AudioRecordingSystem = () => {
    // Private members
    let mediaRecorder;
    let audioChunks = [];
    let recordingStartTime;
    let recordingTimerInterval;
    let audioContext;
    let analyser;
    let stream;
    let isRecording = false;
    let autoSendInterval;
    let sendIntervalMs = 10000; // Default 10 seconds
    let isAutoSendEnabled = true;
    let audioPlayer;
    
    // Audio Processing Component
    const audioProcessor = {
        processAudioChunk: async function(chunks) {
            try {
                const audioBlob = new Blob(chunks, { type: 'audio/wav' });
                
                // Update status
                const statusMessage = `–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç ${new Date().toLocaleTimeString()})...`;
                updateStatus(statusMessage);
                
                // Send to Google Gemini for transcription
                await transcribeAudio(audioBlob);
                
                return true;
            } catch (error) {
                console.error('Error processing audio chunk:', error);
                updateStatus('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ');
                return false;
            }
        }
    };
    
    // Playback Component
    const playbackComponent = {
        setup: function() {
            // Create audio element
            audioPlayer = document.createElement('audio');
            audioPlayer.className = 'audio-player';
            audioPlayer.controls = true;
            document.querySelector('.recorder-controls').appendChild(audioPlayer);
            
            // Set up play button
            playButton.addEventListener('click', () => {
                if (audioPlayer.paused) {
                    audioPlayer.play();
                    playButton.innerHTML = '<span class="play-icon"></span>–ü–∞—É–∑–∞';
                } else {
                    audioPlayer.pause();
                    playButton.innerHTML = '<span class="play-icon"></span>–ü—Ä–æ—Å–ª—É—à–∞—Ç—å';
                }
            });
            
            // Set up audio player events
            audioPlayer.addEventListener('ended', () => {
                playButton.innerHTML = '<span class="play-icon"></span>–ü—Ä–æ—Å–ª—É—à–∞—Ç—å';
            });
        },
        
        updateAudio: function(chunks) {
            const audioBlob = new Blob(chunks, { type: 'audio/wav' });
            const audioUrl = URL.createObjectURL(audioBlob);
            audioPlayer.src = audioUrl;
            audioPlayer.classList.add('visible');
            playButton.disabled = false;
            recognizeButton.disabled = false;
        },
        
        clear: function() {
            audioPlayer.src = '';
            audioPlayer.classList.remove('visible');
            playButton.disabled = true;
            recognizeButton.disabled = true;
            playButton.innerHTML = '<span class="play-icon"></span>–ü—Ä–æ—Å–ª—É—à–∞—Ç—å';
        }
    };
    
    // Visualizer Component
    const visualizerComponent = {
        setup: function() {
            const visualizerContext = visualizer.getContext('2d');
            
            // Set canvas dimensions
            visualizer.width = visualizer.clientWidth;
            visualizer.height = visualizer.clientHeight;
            
            // Initial clear
            visualizerContext.fillStyle = '#f0f2f5';
            visualizerContext.fillRect(0, 0, visualizer.width, visualizer.height);
            
            return visualizerContext;
        },
        
        draw: function(analyserNode, visualizerContext) {
            if (!isRecording) return;
            
            // Get frequency data
            const bufferLength = analyserNode.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyserNode.getByteFrequencyData(dataArray);
            
            // Clear canvas
            visualizerContext.fillStyle = '#f0f2f5';
            visualizerContext.fillRect(0, 0, visualizer.width, visualizer.height);
            
            // Draw bars
            const barWidth = (visualizer.width / bufferLength) * 2.5;
            let x = 0;
            
            for (let i = 0; i < bufferLength; i++) {
                const barHeight = (dataArray[i] / 255) * visualizer.height;
                
                // Use gradient color based on frequency
                const hue = i / bufferLength * 360;
                visualizerContext.fillStyle = `hsl(${hue}, 70%, 60%)`;
                
                visualizerContext.fillRect(x, visualizer.height - barHeight, barWidth, barHeight);
                
                x += barWidth + 1;
            }
            
            // Request next frame
            requestAnimationFrame(() => visualizerComponent.draw(analyserNode, visualizerContext));
        }
    };
    
    // Timer Component
    const timerComponent = {
        start: function(startTime) {
            recordingTimerInterval = setInterval(() => {
                const elapsedTime = Date.now() - startTime;
                const seconds = Math.floor(elapsedTime / 1000);
                const minutes = Math.floor(seconds / 60);
                const remainingSeconds = seconds % 60;
                
                recordingTimer.textContent = `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
            }, 1000);
        },
        
        stop: function() {
            clearInterval(recordingTimerInterval);
        }
    };
    
    // Auto-sending Component
    const autoSendComponent = {
        start: function(intervalMs) {
            // Clear any existing interval
            if (autoSendInterval) {
                clearInterval(autoSendInterval);
            }
            
            // Set up new interval for auto-sending
            autoSendInterval = setInterval(async () => {
                if (isRecording && isAutoSendEnabled && audioChunks.length > 0) {
                    // Create a copy of current chunks and process them
                    const chunksToProcess = [...audioChunks];
                    
                    // Process the audio chunks
                    await audioProcessor.processAudioChunk(chunksToProcess);
                    
                    // Don't clear audioChunks as we want to keep recording
                    // We just want to process what we have so far
                }
            }, intervalMs);
        },
        
        stop: function() {
            if (autoSendInterval) {
                clearInterval(autoSendInterval);
                autoSendInterval = null;
            }
        },
        
        updateInterval: function(newIntervalMs) {
            sendIntervalMs = newIntervalMs;
            if (isRecording && isAutoSendEnabled) {
                this.stop();
                this.start(newIntervalMs);
            }
        },
        
        setEnabled: function(enabled) {
            isAutoSendEnabled = enabled;
            if (isRecording) {
                if (enabled) {
                    this.start(sendIntervalMs);
                } else {
                    this.stop();
                }
            }
        }
    };
    
    // Public methods
    return {
        init: function() {
            // Initialize UI components and settings
            const visualizerContext = visualizerComponent.setup();
            playbackComponent.setup();
            
            // Set up event listeners
            recordButton.addEventListener('click', () => {
                if (!isRecording) {
                    this.startRecording();
                } else {
                    this.stopRecording();
                }
            });
            
            // Set up send frequency slider
            sendFrequency.addEventListener('input', () => {
                const newFrequencySeconds = parseInt(sendFrequency.value);
                frequencyValue.textContent = newFrequencySeconds;
                autoSendComponent.updateInterval(newFrequencySeconds * 1000);
            });
            
            // Set up auto-send toggle
            autoSendToggle.addEventListener('change', () => {
                autoSendComponent.setEnabled(autoSendToggle.checked);
            });
            
            // Set up recognize button
            recognizeButton.addEventListener('click', async () => {
                if (audioChunks.length > 0) {
                    await audioProcessor.processAudioChunk(audioChunks);
                }
            });
            
            // Initialize with default values
            frequencyValue.textContent = sendFrequency.value;
            sendIntervalMs = parseInt(sendFrequency.value) * 1000;
            isAutoSendEnabled = autoSendToggle.checked;
        },
        
        startRecording: async function() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                isRecording = true;
                recordButton.textContent = '‚èπÔ∏è';
                recordButton.classList.add('recording');
                recordingStatus.textContent = '–ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å...';
                
                // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
                visualizerInstance.setupAudioAnalyser(stream);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        // –û–±–Ω–æ–≤–ª—è–µ–º –∞—É–¥–∏–æ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        const audioUrl = URL.createObjectURL(audioBlob);
                        audioPlayer.src = audioUrl;
                        playButton.disabled = false;
                        recognizeButton.disabled = false;
                    }
                };
                
                mediaRecorder.start(1000); // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —á–∞–Ω–∫–∏ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
                recordingStartTime = Date.now();
                timerComponent.start(recordingStartTime);
                
                // –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—Ç–ø—Ä–∞–≤–∫—É, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
                if (autoSendToggle.checked) {
                    autoSendComponent.start(sendIntervalMs);
                }
            } catch (error) {
                console.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏:', error);
                recordingStatus.textContent = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏: ' + error.message;
            }
        },
        
        stopRecording: function() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                recordButton.textContent = 'üé§';
                recordButton.classList.remove('recording');
                recordingStatus.textContent = '–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞';
                
                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
                visualizerInstance.stop();
                
                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
                timerComponent.stop();
                
                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—Ç–ø—Ä–∞–≤–∫—É
                autoSendComponent.stop();
                
                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
                audioPlayer.pause();
                audioPlayer.currentTime = 0;
                playButton.textContent = '‚ñ∂Ô∏è';
            }
        }
    };
};

// Helper function to update status message
function updateStatus(message) {
    recordingStatus.textContent = message;
    recognitionStatus.textContent = message;
}

// Gemini API Key
const GEMINI_API_KEY = 'AIzaSyB8oKZIbyeH7Ttv2kmTn8cEhFiUYKolv3g';
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models';
const GEMINI_MODEL = 'gemini-1.5-flash'; // Using Gemini 1.5 Flash for faster responses

// Convert audio blob to base64
function blobToBase64(blob) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            // Get the base64 string by removing the Data URL prefix
            const base64String = reader.result.split(',')[1];
            resolve(base64String);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
}

// Transcribe audio using Google Gemini API
async function transcribeAudio(audioBlob) {
    try {
        // Convert audio blob to base64
        const audioBase64 = await blobToBase64(audioBlob);
        
        // Prepare the request payload
        const payload = {
            contents: [
                {
                    parts: [
                        {
                            text: "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å—à–∏—Ñ—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –î–∞–π —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."
                        },
                        {
                            inline_data: {
                                mime_type: "audio/wav",
                                data: audioBase64
                            }
                        }
                    ]
                }
            ],
            generation_config: {
                temperature: 0.2,
                top_p: 0.8,
                top_k: 40
            }
        };
        
        // Make the API request
        const response = await fetch(`${GEMINI_API_URL}/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(payload)
        });
        
        // Check if the request was successful
        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`API error: ${errorData.error.message || response.statusText}`);
        }
        
        // Parse the response
        const data = await response.json();
        
        // Extract the transcribed text
        const transcribedText = data.candidates[0].content.parts[0].text;
        
        // Update the conversation text
        updateConversationText(transcribedText);
        
        // Process text with agents
        await processWithAgents(transcribedText);
        
        // Update status
        recognitionStatus.textContent = '–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ';
        
    } catch (error) {
        console.error('Error transcribing audio:', error);
        recognitionStatus.textContent = '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
    }
}

// Update conversation text
function updateConversationText(text) {
    // Get current timestamp
    const timestamp = new Date().toLocaleTimeString();
    
    // Append new text with timestamp
    const formattedText = `<div class="conversation-entry">
        <div class="timestamp">${timestamp}</div>
        <div class="text">${text}</div>
    </div>`;
    
    conversationText.innerHTML += formattedText;
    
    // Scroll to the bottom
    conversationText.scrollTop = conversationText.scrollHeight;
}

// Process text with AI agents
async function processWithAgents(text) {
    try {
        // Process with all agents in parallel
        await Promise.all([
            getAgentResponse(agentJoker, text, '—à—É—Ç–Ω–∏–∫'),
            getAgentResponse(agentSkeptic, text, '—Å–∫–µ–ø—Ç–∏–∫'),
            getAgentResponse(agentSmart, text, '—É–º–Ω–∏–∫')
        ]);
    } catch (error) {
        console.error('Error processing with agents:', error);
    }
}

// Get response from an AI agent
async function getAgentResponse(element, text, agentType) {
    try {
        element.innerHTML = '–û–±—Ä–∞–±–æ—Ç–∫–∞...';
        
        // Prepare prompt based on agent type
        let prompt;
        switch (agentType) {
            case '—à—É—Ç–Ω–∏–∫':
                prompt = `–¢—ã –∞–≥–µ–Ω—Ç "–®—É—Ç–Ω–∏–∫". –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ —á—Ç–æ-—Ç–æ –∑–∞–±–∞–≤–Ω–æ–µ –∏ –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —é–º–æ—Ä–æ–º. –¢–µ–∫—Å—Ç: "${text}"`;
                break;
            case '—Å–∫–µ–ø—Ç–∏–∫':
                prompt = `–¢—ã –∞–≥–µ–Ω—Ç "–°–∫–µ–ø—Ç–∏–∫". –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ç–µ–∫—Å—Ç–µ, –Ω–∞–π—Ç–∏ –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è. –¢–µ–∫—Å—Ç: "${text}"`;
                break;
            case '—É–º–Ω–∏–∫':
                prompt = `–¢—ã –∞–≥–µ–Ω—Ç "–£–º–Ω–∏–∫". –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –¥–∞—Ç—å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ —Ç–µ–∫—Å—Ç—É, —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç, –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –¢–µ–∫—Å—Ç: "${text}"`;
                break;
            default:
                prompt = `–ü—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç: "${text}"`;
        }
        
        // Prepare the request payload
        const payload = {
            contents: [
                {
                    parts: [
                        {
                            text: prompt
                        }
                    ]
                }
            ],
            generation_config: {
                temperature: 0.7,
                top_p: 0.9,
                top_k: 40,
                max_output_tokens: 200
            }
        };
        
        // Make the API request
        const response = await fetch(`${GEMINI_API_URL}/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(payload)
        });
        
        // Check if the request was successful
        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`API error: ${errorData.error.message || response.statusText}`);
        }
        
        // Parse the response
        const data = await response.json();
        
        // Extract the agent's response
        const agentResponse = data.candidates[0].content.parts[0].text;
        
        // Update the agent's response element
        element.innerHTML = agentResponse;
        
    } catch (error) {
        console.error(`Error getting ${agentType} response:`, error);
        element.innerHTML = `–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏`;
    }
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
const visualizerInstance = new AdvancedVisualizer(visualizer, {
    mode: 'waves+particles',
    visualMode: 'spectrum',
    particleCount: 200,
    particleSize: 2,
    murmurmationStrength: 0.3,
    waveColor: '#4285f4',
    backgroundColor: '#000',
    particleColor: '#fff'
});

// Initialize the application
document.addEventListener('DOMContentLoaded', () => {
    const recordingSystem = AudioRecordingSystem();
    recordingSystem.init();
}); 